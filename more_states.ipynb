{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geojson\n",
    "import geopandas\n",
    "import csv\n",
    "import copy\n",
    "import ast\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "from geojson import Feature, Point, FeatureCollection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "\n",
    "def read_geo_gson_file(file_path):\n",
    "    with open(file_path) as f:\n",
    "        gj = geojson.load(f)\n",
    "        features = gj['features']\n",
    "    print(f'Loaded {len(features)} features from {file_path}')\n",
    "    return  features\n",
    "\n",
    "def read_geojson_files(file_paths, base_path = \"./\"):\n",
    "    features = []\n",
    "    for file_path in file_paths:\n",
    "        features += read_geo_gson_file(os.path.join(base_path, file_path))\n",
    "    return features\n",
    "    \n",
    "\n",
    "def read_market_zip_code_usage(market_file_prefix, base_path=\"./source_data\" ):\n",
    "    data_type = \"zip\"\n",
    "    csv_file_path = mapping_data_file_path(market_file_prefix, base_path=base_path, data_type=data_type)\n",
    "    data_rows = []\n",
    "    with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data_rows.append(row)\n",
    "    zip_codes = []\n",
    "    for data_row in data_rows:\n",
    "        zip_codes.append(data_row['Zip'].zfill(5))\n",
    "    print(f'Loaded {len(zip_codes)} zip_codes from {csv_file_path}')\n",
    "    return zip_codes\n",
    "        \n",
    "def read_market_block_group_usage(market_file_prefix, base_path=\"./source_data\" ):\n",
    "    data_type = \"bg\"\n",
    "    csv_file_path = mapping_data_file_path(market_file_prefix, base_path=base_path, data_type=data_type)\n",
    "    data_rows = []\n",
    "    with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data_rows.append(row)\n",
    "    block_groups = []\n",
    "    for data_row in data_rows:\n",
    "        block_groups.append(data_row['BG'].zfill(12))\n",
    "    print(f'Loaded {len(block_groups)} block groups from {csv_file_path}')\n",
    "    return zip_codes\n",
    "        \n",
    "# market_file_prefix = 'DallasFortWorth'\n",
    "# market_prefix= 'dfw'\n",
    "# DallasFortWorth__Mapping_BG_Data.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_BG_Data.csv - the actual zip code data\n",
    "# \n",
    "# DallasFortWorth__Mapping_Zip_Data.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_Zip_Data.csv - the actual block group data\n",
    "# \n",
    "# DallasFortWorth__Mapping_Settings_Transposed File_BG.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_Settings_Transposed_File_BG.csv - segment definitions for Block Groups\n",
    "# DallasFortWorth__Mapping_Settings_Transposed File_Zip.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_Settings_Transposed_File_Zip.csv - segment definitions for Zip Codes\n",
    "\n",
    "def file_type_for_data_type(data_type = \"zip\"):\n",
    "    if data_type == \"zip\": \n",
    "        return \"Zip\"\n",
    "    if data_type == \"bg\":\n",
    "        return \"BG\"\n",
    "\n",
    "# DallasFortWorth__Mapping_BG_Data.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_BG_Data.csv - the actual zip code data\n",
    "# \n",
    "# DallasFortWorth__Mapping_Zip_Data.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_Zip_Data.csv - the actual block group data\n",
    "# \n",
    "def mapping_data_file_path(market_file_prefix, base_path=\"./source_data\", data_type = \"zip\"):\n",
    "    file_type = file_type_for_data_type(data_type = data_type)\n",
    "    return f'{base_path}/{market_file_prefix}__Mapping_{file_type}_Data.csv'\n",
    "\n",
    "# DallasFortWorth__Mapping_Settings_Transposed File_BG.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_Settings_Transposed_File_BG.csv - segment definitions for Block Groups\n",
    "# DallasFortWorth__Mapping_Settings_Transposed File_Zip.csv\n",
    "# ./source_data/{market_file_prefix}__Mapping_Settings_Transposed_File_Zip.csv - segment definitions for Zip Codes\n",
    "def map_settings_data_file_path(market_file_prefix, base_path=\"./source_data\", data_type = \"zip\"):\n",
    "    file_type = file_type_for_data_type(data_type = data_type)\n",
    "    return f'{base_path}/{market_file_prefix}__Mapping_Settings_Transposed File_{file_type}.csv'\n",
    "\n",
    "def published_map_data_path(market_prefix,  data_type = \"zip\", published_data_base_path=\"./public\"):\n",
    "    return f'{published_data_base_path}/{market_prefix}_{data_type}_data.json'\n",
    "\n",
    "def published_map_settings_path(market_prefix,  data_type = \"zip\", published_data_base_path=\"./public\"):\n",
    "    return f'{published_data_base_path}/{market_prefix}_{data_type}_settings_data.json'\n",
    "\n",
    "def published_map_labels_path(market_prefix,  data_type = \"zip\", published_data_base_path=\"./public\"):\n",
    "    return f'{published_data_base_path}/{market_prefix}_{data_type}_labels.json'\n",
    "\n",
    "def read_mapping_data(market_file_prefix, base_path='./source_data', data_type='zip'):\n",
    "    data_rows = []\n",
    "    csv_file_path = mapping_data_file_path(market_file_prefix, base_path=base_path, data_type = data_type)\n",
    "    with open(csv_file_path) as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data_rows.append(row)\n",
    "    print(f'Loaded {len(data_rows)} data rows from {csv_file_path}')\n",
    "    return data_rows\n",
    "\n",
    "def create_zip_features(features, zip_data_rows):\n",
    "    new_features_to_keep = []\n",
    "    for data_row in zip_data_rows:\n",
    "        zip_code = data_row['Zip'].zfill(5)\n",
    "        # find the associated feature\n",
    "        for feature in features:\n",
    "            if feature['properties'][\"ZCTA5CE10\"] == zip_code:\n",
    "                new_feature = copy.deepcopy(feature)\n",
    "                for key in data_row.keys():\n",
    "                    if key != 'Zip':\n",
    "                        if data_row[key]:\n",
    "                            if data_row[key] != 'inf':\n",
    "                                new_feature['properties'][key] =  ast.literal_eval(data_row[key].replace(',',''))\n",
    "                new_features_to_keep.append(new_feature)\n",
    "                break\n",
    "    print(f'Processed {len(new_features_to_keep)} features to use')\n",
    "    return new_features_to_keep\n",
    "\n",
    "def create_bg_features(features, bg_data_rows):\n",
    "    new_features_to_keep = []\n",
    "    for data_row in bg_data_rows:\n",
    "        block_group = str(data_row['BG']).zfill(12)\n",
    "        # find the associated feature\n",
    "        found = False\n",
    "        for feature in features:\n",
    "            if feature['properties'][\"GEOID10\"] == block_group:\n",
    "                found = True\n",
    "                new_feature = copy.deepcopy(feature)\n",
    "                for key in data_row.keys():\n",
    "                    if key != 'BG':\n",
    "                        if data_row[key] and data_row[key] != 'inf':\n",
    "                            new_feature['properties'][key] =  ast.literal_eval(data_row[key].replace(',',''))\n",
    "                new_features_to_keep.append(new_feature)\n",
    "                break\n",
    "    #         if found == False:\n",
    "    #             print(f'failed: {block_group}')\n",
    "    print(f'Processed {len(new_features_to_keep)} features to use')\n",
    "    return new_features_to_keep\n",
    "\n",
    "def create_geojson(features):\n",
    "    print(f'Created GeoJson with  {len(features)} features')\n",
    "    return FeatureCollection(features)\n",
    "\n",
    "def write_geojson(geojson_data, market_prefix, data_type='zip',published_data_base_path = \"./public\"):\n",
    "    geojson_string = geojson.dumps(geojson_data, sort_keys=True)\n",
    "    f = open(f'{published_data_base_path}/{market_prefix}_{data_type}_data.json', \"w\")\n",
    "    f.write(geojson_string)\n",
    "    f.close()\n",
    "    print(f'Wrote geojson data to  {published_data_base_path}/{market_prefix}_{data_type}_data.json')\n",
    "    \n",
    "def read_map_settings(market_file_prefix, base_path=\"./source_data\", data_type = \"zip\"):\n",
    "    data_rows = []\n",
    "    csv_file_path = map_settings_data_file_path(market_file_prefix, base_path=base_path, data_type = data_type)\n",
    "    print(csv_file_path)\n",
    "    with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            print(row)\n",
    "            data_rows.append(row)\n",
    "    print(f'Loaded {len(data_rows)} data rows from {csv_file_path}')   \n",
    "    return data_rows\n",
    "\n",
    "def write_settings_data(settings_data, market_file_prefix, base_path=\"./public\", data_type = \"zip\"):\n",
    "    processed_settings_data = OrderedDict()\n",
    "    for row in settings_data:\n",
    "        processed_settings_data[row['Bain_Short_Name']] = row\n",
    "    json_string = json.dumps(processed_settings_data, indent = 2, sort_keys=False)\n",
    "    settings_data_file_path = published_map_settings_path(market_file_prefix,  data_type = data_type, published_data_base_path=base_path)\n",
    "    f = open(settings_data_file_path, \"w\")\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "    print(f'Wrote settings data rows to {settings_data_file_path}') \n",
    "    \n",
    "def create_zip_labels(market_file_prefix, base_path=\"./source_data\" , data_type = \"zip\" , published_data_base_path=\"./public\"):\n",
    "    data_rows = []\n",
    "    #     csv_file_path = './DFW_Mapping_data.csv'\n",
    "    csv_file_path = mapping_data_file_path(market_file_prefix, base_path=base_path, data_type = \"zip\")\n",
    "    with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data_rows.append(row)\n",
    "\n",
    "    features = []\n",
    "    for data_row in data_rows:\n",
    "        feature =  { \n",
    "            \"type\": \"Feature\", \n",
    "            \"properties\": {\n",
    "                \"id\": data_row['Zip']\n",
    "            },\n",
    "            \"geometry\": { \n",
    "                \"type\": \"Point\", \n",
    "                \"coordinates\": [ float(data_row['intptlong']), float(data_row['intptlat']) ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        features.append(feature)\n",
    "    geo_json = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "    json_string = json.dumps(geo_json, indent = 2, sort_keys=True)\n",
    "    output_file_path = published_map_labels_path(market_prefix,  data_type , published_data_base_path=\"./public\")\n",
    "    f = open(output_file_path, \"w\")\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "    print(f'Wrote geojson labels data to  {output_file_path}')\n",
    "\n",
    "def create_bg_labels(market_file_prefix, base_path=\"./source_data\" , data_type = \"bg\" , published_data_base_path=\"./public\"):\n",
    "    data_rows = []\n",
    "    #     csv_file_path = './DFW_Mapping_data.csv'\n",
    "    csv_file_path = mapping_data_file_path(market_file_prefix, base_path=base_path, data_type = \"bg\")\n",
    "    with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data_rows.append(row)\n",
    "\n",
    "    features = []\n",
    "    for data_row in data_rows:\n",
    "        feature =  { \n",
    "            \"type\": \"Feature\", \n",
    "            \"properties\": {\n",
    "                \"id\": data_row['BG']\n",
    "            },\n",
    "            \"geometry\": { \n",
    "                \"type\": \"Point\", \n",
    "                \"coordinates\": [ float(data_row['LONG']), float(data_row['LAT']) ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        features.append(feature)\n",
    "    geo_json = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "    json_string = json.dumps(geo_json, indent = 2, sort_keys=True)\n",
    "    output_file_path = published_map_labels_path(market_prefix,  data_type , published_data_base_path=\"./public\")\n",
    "    f = open(output_file_path, \"w\")\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "    print(f'Wrote geojson labels data to  {output_file_path}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_base_path = \"'/Users/alanmccann/Dropbox/bain/\"\n",
    "markets_data = [\n",
    "    {\n",
    "        \"market_file_prefix\":'CharlestonSC',\n",
    "        \"market_prefix\": \"charleston\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": ['sc_south_carolina_zip_codes_geo.min.json'],\n",
    "            \"bg\": ['tl_2010_45_bg10.json']\n",
    "      },\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'DallasFortWorth',\n",
    "        \"market_prefix\": \"dfw\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": ['tx_texas_zip_codes_geo.min.json'],\n",
    "            \"bg\": ['tl_2010_48_bg10.json']\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'WashingtonDC',\n",
    "        \"market_prefix\": \"dc\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                        'dc_district_of_columbia_zip_codes_geo.min.json',\n",
    "                        'va_virginia_zip_codes_geo.min.json',\n",
    "                        'md_maryland_zip_codes_geo.min.json',\n",
    "                  ],\n",
    "            \"bg\": [\n",
    "                'tl_2010_11_bg10.json',\n",
    "                'tl_2010_24_bg10.json',\n",
    "                'tl_2010_51_bg10.json',\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Denver',\n",
    "        \"market_prefix\": \"denver\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": ['co_colorado_zip_codes_geo.min.json'],\n",
    "             \"bg\": ['tl_2010_08_bg10.json']\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'DallasFortWorth',\n",
    "        \"market_prefix\": \"dfw\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": ['tx_texas_zip_codes_geo.min.json'],\n",
    "            \"bg\": ['tl_2010_48_bg10.json']\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'KansasCity',\n",
    "        \"market_prefix\": \"kansascity\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'ks_kansas_zip_codes_geo.min.json',\n",
    "                'mo_missouri_zip_codes_geo.min.json'\n",
    "              ],\n",
    "             \"bg\": [\n",
    "               'tl_2010_20_bg10.json',\n",
    "               'tl_2010_29_bg10.json',\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Minnesota',\n",
    "        \"market_prefix\": \"minnesota\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'mn_minnesota_zip_codes_geo.min.json',\n",
    "              ],\n",
    "             \"bg\": [\n",
    "               'tl_2010_27_bg10.json',\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'NewYorkCity',\n",
    "        \"market_prefix\": \"nyc\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'ny_new_york_zip_codes_geo.min.json',\n",
    "                'nj_new_jersey_zip_codes_geo.min.json',\n",
    "                'pa_pennsylvania_zip_codes_geo.min.json',\n",
    "                'ct_connecticut_zip_codes_geo.min.json'\n",
    "            ],\n",
    "            \"bg\": [\n",
    "                'tl_2010_36_bg10.json',\n",
    "                'tl_2010_34_bg10.json',\n",
    "                'tl_2010_42_bg10.json',\n",
    "                'tl_2010_09_bg10.json',\n",
    "            ]\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'SanDiego',\n",
    "        \"market_prefix\": \"sandiego\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'ca_california_zip_codes_geo.min.json',\n",
    "              ],\n",
    "             \"bg\": [\n",
    "               'tl_2010_06_bg10.json',\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Seattle',\n",
    "        \"market_prefix\": \"seattle\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'wa_washington_zip_codes_geo.min.json',\n",
    "              ],\n",
    "             \"bg\": [\n",
    "               'tl_2010_53_bg10.json',\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Seattle',\n",
    "        \"market_prefix\": \"seattle\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'wa_washington_zip_codes_geo.min.json',\n",
    "              ],\n",
    "             \"bg\": [\n",
    "               'tl_2010_53_bg10.json',\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Tampa',\n",
    "        \"market_prefix\": \"tampa\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'fl_florida_zip_codes_geo.min.json',\n",
    "              ],\n",
    "             \"bg\": [\n",
    "               'tl_2010_12_bg10.json',\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Texas',\n",
    "        \"market_prefix\": \"texas\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'tx_texas_zip_codes_geo.min.json'\n",
    "            ],\n",
    "            \"bg\": [\n",
    "                'tl_2010_48_bg10.json'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"market_file_prefix\":'Waco',\n",
    "        \"market_prefix\": \"waco\",\n",
    "        \"geojson_files\": {\n",
    "            \"zip\": [\n",
    "                'tx_texas_zip_codes_geo.min.json'\n",
    "            ],\n",
    "            \"bg\": [\n",
    "                'tl_2010_48_bg10.json'\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "markets_data[0]\n",
    "\n",
    "# {\n",
    "#  \"08\": \"Colorado\",\n",
    "#   \"09\": \"Connecticut\",\n",
    "#   \"11\": \"District of Columbia\",\n",
    "#   \"24\": \"Maryland\",\n",
    "#   \"34\": \"New Jersey\",\n",
    "#   \"36\": \"New York\",\n",
    "#   \"42\": \"Pennsylvania\",\n",
    "#   \"48\": \"Texas\",\n",
    "#   \"51\": \"Virginia\",\n",
    "\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_data_base_path = \"./source_data\"\n",
    "source_data_base_path = \"/Users/alanmccann/Dropbox/bain/16th_run\"\n",
    "published_data_base_path = \"./public\"\n",
    "geojson_files_base_path = '/Users/alanmccann/Dropbox/bain/map_source_data'\n",
    "\n",
    "for market in markets_data:\n",
    "    market_file_prefix = market['market_file_prefix']\n",
    "    market_prefix = market['market_prefix']\n",
    "    data_type = 'zip'\n",
    "    print(f'market: {market_prefix}')\n",
    "    geojson_files = market['geojson_files'][\"zip\"]\n",
    "    zip_codes = read_market_zip_code_usage(market_file_prefix, base_path=source_data_base_path )\n",
    "    zip_data_rows = read_mapping_data(market_file_prefix, source_data_base_path, data_type)\n",
    "    features = read_geojson_files(geojson_files, base_path=geojson_files_base_path)\n",
    "    features_to_use = create_zip_features(features, zip_data_rows)\n",
    "    new_geojson = create_geojson(features_to_use)\n",
    "    write_geojson(new_geojson, market_prefix, data_type, published_data_base_path=published_data_base_path)\n",
    "    map_settings_data = read_map_settings(market_file_prefix, base_path=source_data_base_path, data_type = \"zip\")\n",
    "    print(map_settings_data)\n",
    "    write_settings_data(map_settings_data, market_prefix, base_path=published_data_base_path, data_type = \"zip\")\n",
    "\n",
    "\n",
    "    create_zip_labels(market_file_prefix, base_path=source_data_base_path , data_type = \"zip\" , published_data_base_path=published_data_base_path)\n",
    "    # data_type = 'bg'\n",
    "    data_type = 'bg'\n",
    "    geojson_files = market['geojson_files'][\"bg\"]\n",
    "    block_groups = read_market_block_group_usage(market_file_prefix, base_path=source_data_base_path )\n",
    "    block_group_rows = read_mapping_data(market_file_prefix, source_data_base_path, data_type)\n",
    "    features = read_geojson_files(geojson_files, base_path=geojson_files_base_path)\n",
    "    features_to_use = create_bg_features(features, block_group_rows)\n",
    "    new_geojson = create_geojson(features_to_use)\n",
    "    write_geojson(new_geojson, market_prefix, data_type, published_data_base_path=published_data_base_path)\n",
    "\n",
    "    #  settings\n",
    "    map_settings_data = read_map_settings(market_file_prefix, base_path=source_data_base_path, data_type = \"bg\")\n",
    "    write_settings_data(map_settings_data, market_prefix, base_path=published_data_base_path, data_type = \"bg\")\n",
    "    create_bg_labels(market_file_prefix, base_path=source_data_base_path , data_type = \"bg\" , published_data_base_path=published_data_base_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
