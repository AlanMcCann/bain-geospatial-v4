{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geojson\n",
    "import geopandas\n",
    "# Data from https://github.com/OpenDataDE/State-zip-code-GeoJSON\n",
    "# Opening JSON file\n",
    "f = open('/Users/alanmccann/Dropbox/bain/tx_texas_zip_codes_geo.min.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "# for i in data['emp_details']:\n",
    "#     print(i)\n",
    "print(len(data[\"features\"]))\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Files\n",
    "# {market}_Mapping_Data.csv - the actual data\n",
    "# {market}_Mapping_Settings_transposed.csv - segment definitions\n",
    "# {market}_Settings.csv - overall map settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './DFW_Mapping_data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "dfw_zip_codes = []\n",
    "for data_row in data_rows:\n",
    "    dfw_zip_codes.append(data_row['Zip'].zfill(5))\n",
    "dfw_zip_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/tx_texas_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "features = gj['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = []\n",
    "for feature in features:\n",
    "    if feature['properties'][\"ZCTA5CE10\"] in dfw_zip_codes:\n",
    "        features_to_keep.append(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-saturn",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './DFW_Mapping_Data.csv'\n",
    "with open(csv_file_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ast\n",
    "new_features_to_keep = []\n",
    "for data_row in data_rows:\n",
    "    zip_code = data_row['Zip'].zfill(5)\n",
    "    # find the associated feature\n",
    "    for feature in features_to_keep:\n",
    "        if feature['properties'][\"ZCTA5CE10\"] == zip_code:\n",
    "            new_feature = copy.deepcopy(feature)\n",
    "            for key in data_row.keys():\n",
    "                if key != 'Zip':\n",
    "                    if data_row[key]:\n",
    "                        new_feature['properties'][key] =  ast.literal_eval(data_row[key].replace(',',''))\n",
    "            new_features_to_keep.append(new_feature)\n",
    "            print(new_feature)\n",
    "            break\n",
    "print(new_features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geojson = FeatureCollection(new_features_to_keep) \n",
    "new_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = geojson.dumps(new_geojson, sort_keys=True)\n",
    "dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "geojson_string = geojson.dumps(new_geojson, sort_keys=True)\n",
    "f = open(\"public/dfw_data.json\", \"w\")\n",
    "f.write(geojson_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './DFW_Mapping_Settings_Transposed.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "settings_data = {}\n",
    "for row in data_rows:\n",
    "    settings_data[row['Bain_Short_Name']] = row\n",
    "print(json.dumps(settings_data, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(settings_data, indent = 2, sort_keys=True)\n",
    "f = open(\"public/dfw_settings_data.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labels Data\n",
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './DFW_Mapping_data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "\n",
    "features = []\n",
    "for data_row in data_rows:\n",
    "    feature =  { \n",
    "        \"type\": \"Feature\", \n",
    "        \"properties\": {\n",
    "            \"id\": data_row['Zip']\n",
    "        },\n",
    "        \"geometry\": { \n",
    "            \"type\": \"Point\", \n",
    "            \"coordinates\": [ float(data_row['intptlong']), float(data_row['intptlat']) ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    features.append(feature)\n",
    "geo_json = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "json_string = json.dumps(geo_json, indent = 2, sort_keys=True)\n",
    "f = open(\"public/dfw_labels.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denver\n",
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './Denver_Mapping_data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "denver_zip_codes = []\n",
    "for data_row in data_rows:\n",
    "    denver_zip_codes.append(data_row['Zip'].zfill(5))\n",
    "denver_zip_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/co_colorado_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "features = gj['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = []\n",
    "for feature in features:\n",
    "    if feature['properties'][\"ZCTA5CE10\"] in denver_zip_codes:\n",
    "        features_to_keep.append(feature)\n",
    "len(features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './Denver_Mapping_Data.csv'\n",
    "with open(csv_file_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ast\n",
    "new_features_to_keep = []\n",
    "for data_row in data_rows:\n",
    "    zip_code = data_row['Zip'].zfill(5)\n",
    "    # find the associated feature\n",
    "    for feature in features_to_keep:\n",
    "        if feature['properties'][\"ZCTA5CE10\"] == zip_code:\n",
    "            new_feature = copy.deepcopy(feature)\n",
    "            for key in data_row.keys():\n",
    "                if key != 'Zip':\n",
    "                    if data_row[key]:\n",
    "                        new_feature['properties'][key] =  ast.literal_eval(data_row[key].replace(',',''))\n",
    "            new_features_to_keep.append(new_feature)\n",
    "            print(new_feature)\n",
    "            break\n",
    "print(new_features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geojson = FeatureCollection(new_features_to_keep) \n",
    "new_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_string = geojson.dumps(new_geojson, sort_keys=True)\n",
    "f = open(\"public/denver_data.json\", \"w\")\n",
    "f.write(geojson_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './Denver_Mapping_Settings_Transposed.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "settings_data = {}\n",
    "for row in data_rows:\n",
    "    settings_data[row['Bain_Short_Name']] = row\n",
    "print(json.dumps(settings_data, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(settings_data, indent = 2, sort_keys=True)\n",
    "f = open(\"public/denver_settings_data.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labels Data\n",
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './Denver_Mapping_data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "\n",
    "features = []\n",
    "for data_row in data_rows:\n",
    "    feature =  { \n",
    "        \"type\": \"Feature\", \n",
    "        \"properties\": {\n",
    "            \"id\": data_row['Zip']\n",
    "        },\n",
    "        \"geometry\": { \n",
    "            \"type\": \"Point\", \n",
    "            \"coordinates\": [ float(data_row['intptlong']), float(data_row['intptlat']) ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    features.append(feature)\n",
    "geo_json = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "json_string = json.dumps(geo_json, indent = 2, sort_keys=True)\n",
    "f = open(\"public/denver_labels.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './WashingtonDC_Mapping_Data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "dc_zip_codes = []\n",
    "for data_row in data_rows:\n",
    "    dc_zip_codes.append(data_row['Zip'].zfill(5))\n",
    "dc_zip_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/dc_district_of_columbia_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "dc_features = gj['features']\n",
    "dc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/md_maryland_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "md_features = gj['features']\n",
    "md_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/va_virginia_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "va_features = gj['features']\n",
    "va_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dc_features + md_features + va_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = []\n",
    "for feature in features:\n",
    "    if feature['properties'][\"ZCTA5CE10\"] in dc_zip_codes:\n",
    "        features_to_keep.append(feature)\n",
    "len(features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-short",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './WashingtonDC_Mapping_Data.csv'\n",
    "with open(csv_file_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ast\n",
    "new_features_to_keep = []\n",
    "for data_row in data_rows:\n",
    "    zip_code = data_row['Zip'].zfill(5)\n",
    "    # find the associated feature\n",
    "    for feature in features_to_keep:\n",
    "        if feature['properties'][\"ZCTA5CE10\"] == zip_code:\n",
    "            new_feature = copy.deepcopy(feature)\n",
    "            for key in data_row.keys():\n",
    "                if key != 'Zip':\n",
    "                    if data_row[key]:\n",
    "                        new_feature['properties'][key] =  ast.literal_eval(data_row[key].replace(',',''))\n",
    "            new_features_to_keep.append(new_feature)\n",
    "            print(new_feature)\n",
    "            break\n",
    "print(new_features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geojson = FeatureCollection(new_features_to_keep) \n",
    "new_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_string = geojson.dumps(new_geojson, sort_keys=True)\n",
    "f = open(\"public/dc_data.json\", \"w\")\n",
    "f.write(geojson_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './WashingtonDC_Mapping_Settings_Transposed.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-sherman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "settings_data = {}\n",
    "for row in data_rows:\n",
    "    settings_data[row['Bain_Short_Name']] = row\n",
    "print(json.dumps(settings_data, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(settings_data, indent = 2, sort_keys=True)\n",
    "f = open(\"public/dc_settings_data.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labels Data\n",
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './WashingtonDC_Mapping_data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "\n",
    "features = []\n",
    "for data_row in data_rows:\n",
    "    feature =  { \n",
    "        \"type\": \"Feature\", \n",
    "        \"properties\": {\n",
    "            \"id\": data_row['Zip']\n",
    "        },\n",
    "        \"geometry\": { \n",
    "            \"type\": \"Point\", \n",
    "            \"coordinates\": [ float(data_row['intptlong']), float(data_row['intptlat']) ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    features.append(feature)\n",
    "geo_json = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "json_string = json.dumps(geo_json, indent = 2, sort_keys=True)\n",
    "f = open(\"public/dc_labels.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './NewYorkCity_Mapping_Data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "nyc_zip_codes = []\n",
    "for data_row in data_rows:\n",
    "    nyc_zip_codes.append(data_row['Zip'].zfill(5))\n",
    "nyc_zip_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-picking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NY State\n",
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/ny_new_york_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "ny_features = gj['features']\n",
    "ny_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NJ State\n",
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/nj_new_jersey_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "nj_features = gj['features']\n",
    "nj_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PA State\n",
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/pa_pennsylvania_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "pa_features = gj['features']\n",
    "pa_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CT State\n",
    "# https://pypi.org/project/geojson/#featurecollection\n",
    "file_path = '/Users/alanmccann/Dropbox/bain/ct_connecticut_zip_codes_geo.min.json'\n",
    "import geojson\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "with open(file_path) as f:\n",
    "    gj = geojson.load(f)\n",
    "ct_features = gj['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ny_features + nj_features + ct_features + pa_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = []\n",
    "for feature in features:\n",
    "    if feature['properties'][\"ZCTA5CE10\"] in nyc_zip_codes:\n",
    "        features_to_keep.append(feature)\n",
    "len(features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-macro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './NewYorkCity_Mapping_Data.csv'\n",
    "with open(csv_file_path) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ast\n",
    "new_features_to_keep = []\n",
    "for data_row in data_rows:\n",
    "    zip_code = data_row['Zip'].zfill(5)\n",
    "    print(zip_code)\n",
    "    # find the associated feature\n",
    "    for feature in features_to_keep:\n",
    "        if feature['properties'][\"ZCTA5CE10\"] == zip_code:\n",
    "            new_feature = copy.deepcopy(feature)\n",
    "            for key in data_row.keys():\n",
    "                if key != 'Zip':\n",
    "                    if data_row[key]:\n",
    "                        new_feature['properties'][key] =  ast.literal_eval(data_row[key].replace(',',''))\n",
    "            new_features_to_keep.append(new_feature)\n",
    "            print(new_feature)\n",
    "            break\n",
    "len(new_features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_features_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_geojson = FeatureCollection(new_features_to_keep) \n",
    "new_geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_string = geojson.dumps(new_geojson, sort_keys=True)\n",
    "f = open(\"public/nyc_data.json\", \"w\")\n",
    "f.write(geojson_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './NewYorkCity_Mapping_Settings_Transposed.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "settings_data = {}\n",
    "for row in data_rows:\n",
    "    settings_data[row['Bain_Short_Name']] = row\n",
    "print(json.dumps(settings_data, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = json.dumps(settings_data, indent = 2, sort_keys=True)\n",
    "f = open(\"public/nyc_settings_data.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Labels Data\n",
    "import csv\n",
    "data_rows = []\n",
    "csv_file_path = './NewYorkCity_Mapping_data.csv'\n",
    "with open(csv_file_path, encoding='utf-8-sig') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        data_rows.append(row)\n",
    "\n",
    "features = []\n",
    "for data_row in data_rows:\n",
    "    feature =  { \n",
    "        \"type\": \"Feature\", \n",
    "        \"properties\": {\n",
    "            \"id\": data_row['Zip']},\n",
    "        \"geometry\": { \n",
    "            \"type\": \"Point\", \n",
    "            \"coordinates\": [ float(data_row['intptlong']), float(data_row['intptlat']) ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    features.append(feature)\n",
    "geo_json = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": features\n",
    "}\n",
    "json_string = json.dumps(geo_json, indent = 2, sort_keys=True)\n",
    "f = open(\"public/nyc_labels.json\", \"w\")\n",
    "f.write(json_string)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-organic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
